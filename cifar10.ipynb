{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OrmH99i24qH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok7uJxRRGXn"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import RMSprop\n",
        "import pylab as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrjw9n4Qwhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270a82f3-0813-464b-ab06-70564cb7d47f"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "x_train = x_train.reshape(50000, 3072)\n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize to 0 to 1 range\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GSz1VZbSuJR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2fa91a73-cd3a-4e31-cd28-7f2cef43980b"
      },
      "source": [
        "print(\"Label:\",y_test[12:13])\n",
        "plt.imshow(x_test[12:13].reshape(32,32,3), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djmtkLpkTXil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee7cdd5-23a0-44cf-c0ed-afbe02a3b5b5"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2048,activation='relu', input_shape=(3072,)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "#multiclassthereforecategoricalcrossentropy\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 2048)              6293504   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 8,992,810\n",
            "Trainable params: 8,992,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 4s 8ms/step - loss: 2.7727 - accuracy: 0.1601 - val_loss: 1.8877 - val_accuracy: 0.3158\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9172 - accuracy: 0.3093 - val_loss: 1.8165 - val_accuracy: 0.3395\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7961 - accuracy: 0.3578 - val_loss: 1.7424 - val_accuracy: 0.3664\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7297 - accuracy: 0.3746 - val_loss: 1.7981 - val_accuracy: 0.3673\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.6666 - accuracy: 0.4020 - val_loss: 1.6365 - val_accuracy: 0.4129\n",
            "Test loss: 1.6365256309509277\n",
            "Test accuracy: 0.41290000081062317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ok_zATxXIkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f77d62-ec32-4260-d786-6a8f36fc7b58"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4096,activation='tanh', input_shape=(3072,)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 4096)              12587008  \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 17,383,466\n",
            "Trainable params: 17,383,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 4s 8ms/step - loss: 2.2308 - accuracy: 0.1618 - val_loss: 1.9381 - val_accuracy: 0.2693\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9451 - accuracy: 0.2641 - val_loss: 1.8579 - val_accuracy: 0.3021\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8792 - accuracy: 0.2987 - val_loss: 1.8209 - val_accuracy: 0.3314\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8497 - accuracy: 0.3178 - val_loss: 1.8148 - val_accuracy: 0.3254\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8164 - accuracy: 0.3346 - val_loss: 1.8030 - val_accuracy: 0.3381\n",
            "Test loss: 1.8029625415802002\n",
            "Test accuracy: 0.33809998631477356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YTwFbKrXse_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9261e313-cbea-4f07-98ef-98a24947db47"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4096,activation='relu', input_shape=(3072,)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 4096)              12587008  \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 17,383,466\n",
            "Trainable params: 17,383,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 4s 8ms/step - loss: 2.3027 - accuracy: 0.1776 - val_loss: 1.8302 - val_accuracy: 0.3234\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7845 - accuracy: 0.3497 - val_loss: 1.7358 - val_accuracy: 0.3694\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.6807 - accuracy: 0.3981 - val_loss: 1.6193 - val_accuracy: 0.4232\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.6143 - accuracy: 0.4189 - val_loss: 1.5559 - val_accuracy: 0.4425\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.5418 - accuracy: 0.4527 - val_loss: 1.5142 - val_accuracy: 0.4621\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4981 - accuracy: 0.4643 - val_loss: 1.5141 - val_accuracy: 0.4625\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4465 - accuracy: 0.4842 - val_loss: 1.5114 - val_accuracy: 0.4491\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4190 - accuracy: 0.4910 - val_loss: 1.4650 - val_accuracy: 0.4761\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3901 - accuracy: 0.5020 - val_loss: 1.4806 - val_accuracy: 0.4821\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3531 - accuracy: 0.5156 - val_loss: 1.4375 - val_accuracy: 0.4905\n",
            "Test loss: 1.437535047531128\n",
            "Test accuracy: 0.49050000309944153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETTxYi1VYTyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54de917-7420-4a28-8e52-730b886cfd77"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1024,activation='relu', input_shape=(3072,)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 4,797,482\n",
            "Trainable params: 4,797,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2092 - accuracy: 0.1581 - val_loss: 1.8909 - val_accuracy: 0.2937\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.8455 - accuracy: 0.3175 - val_loss: 1.7267 - val_accuracy: 0.3785\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.7092 - accuracy: 0.3815 - val_loss: 1.6849 - val_accuracy: 0.3864\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.6347 - accuracy: 0.4087 - val_loss: 1.6421 - val_accuracy: 0.4041\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.5601 - accuracy: 0.4405 - val_loss: 1.5223 - val_accuracy: 0.4586\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.4888 - accuracy: 0.4624 - val_loss: 1.4997 - val_accuracy: 0.4652\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.4627 - accuracy: 0.4750 - val_loss: 1.5095 - val_accuracy: 0.4587\n",
            "Epoch 8/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.4183 - accuracy: 0.4893 - val_loss: 1.4574 - val_accuracy: 0.4784\n",
            "Epoch 9/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3650 - accuracy: 0.5079 - val_loss: 1.4860 - val_accuracy: 0.4679\n",
            "Epoch 10/15\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3560 - accuracy: 0.5081 - val_loss: 1.4318 - val_accuracy: 0.4956\n",
            "Epoch 11/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3136 - accuracy: 0.5287 - val_loss: 1.4127 - val_accuracy: 0.5025\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2891 - accuracy: 0.5407 - val_loss: 1.4509 - val_accuracy: 0.4839\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2437 - accuracy: 0.5537 - val_loss: 1.4054 - val_accuracy: 0.5051\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2011 - accuracy: 0.5675 - val_loss: 1.3930 - val_accuracy: 0.5112\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1746 - accuracy: 0.5792 - val_loss: 1.4040 - val_accuracy: 0.5117\n",
            "Test loss: 1.4040462970733643\n",
            "Test accuracy: 0.5116999745368958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XHfHM1T4rMZ"
      },
      "source": [
        "#summarizehistory\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCuYVKL-5soU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "506b9f59-a862-4fed-995e-1ca0e01ce802"
      },
      "source": [
        "#history = model.fit(x_train, y_train, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-490a0e454a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ThlAa2G40aa"
      },
      "source": [
        "#nexttwocellforcifar100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5FWnvub4qG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "26aecf60-cf0f-435a-a33c-69e086dbec1f"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "x_train = x_train.reshape(50000, 3072)\n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize to 0 to 1 range\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-625e540c5ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the data, split between train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cifar100' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrOjh3lG4-56"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4096,activation='relu', input_shape=(3072,)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}